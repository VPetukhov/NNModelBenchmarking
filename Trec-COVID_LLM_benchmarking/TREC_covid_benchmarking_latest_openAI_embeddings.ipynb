{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--xau9rq0RVw"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "else:\n",
        "    print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "GSnRyMJhEkrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "fXkpfEBuUcYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TCKJ-eZPxOL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from sklearn.metrics import ndcg_score\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "drive_root = '/content/drive/MyDrive/Colab/vp'\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_ifVzaozosy"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, list_datasets\n",
        "# BeIR/trec-covid\n",
        "# BeIR/trec-covid-qrels\n",
        "# BeIR/trec-covid-generated-queries\n",
        "# BeIR/trec-news-generated-queries\n",
        "corpus_dataset = load_dataset(\"BeIR/trec-covid\", \"corpus\")['corpus']\n",
        "queries_dataset = load_dataset(\"BeIR/trec-covid\", \"queries\")['queries']\n",
        "qrels_dataset = load_dataset(\"BeIR/trec-covid-qrels\")['test']\n",
        "corpus_dataset, queries_dataset, qrels_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPMVtznfNZyd"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install git+https://github.com/UKPLab/sentence-transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall sentence-transformers"
      ],
      "metadata": {
        "id": "yd2eouU0gVP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efs7ajSbRnj"
      },
      "source": [
        "# MiniLM inferense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDN5cvN2SL6s"
      },
      "outputs": [],
      "source": [
        "# !pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3kAyRTV0oMm"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"Muennighoff/SGPT-1.3B-weightedmean-nli-bitfit\")  # This one requires latest installation of sentence-transformers straight from the repo\n",
        "# model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN1Yzvr63bYM"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# import pickle\n",
        "# drive.mount('/content/drive')\n",
        "# drive_root = '/content/drive/MyDrive/Colab/vp'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CFf1cV1h1mF"
      },
      "source": [
        "### Embedding calculation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGXLe2n3l6eR"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'SGPT-1.3B-weightedmean-nli-bitfit'\n",
        "# 1,2 - all\n",
        "# 3 ms-macro | misuse | bs\n",
        "# def encode_batch(batch_start: int, batch_end: int):\n",
        "#     subsection_of_dataset = corpus_dataset[batch_start:batch_end]\n",
        "#     sentences = [f\"{title}. {text}\" for title, text in zip(subsection_of_dataset['title'], subsection_of_dataset['text'])]\n",
        "#     sentence_embeddings = model.encode(sentences, show_progress_bar=True)\n",
        "#     np.save(f'{drive_root}/{experiment_name}_embeddings_{batch_start}:{batch_end}.npy', sentence_embeddings)\n",
        "def encode_queries_batch(batch_start: int, batch_end: int):\n",
        "    subsection_of_dataset = queries_dataset[batch_start:batch_end]\n",
        "    query_embeddings = model.encode(subsection_of_dataset['text'], show_progress_bar=True)\n",
        "    np.save(f'{drive_root}/{experiment_name}_query_embeddings_{batch_start}:{batch_end}.npy', query_embeddings)   \n",
        "\n",
        "def encode_documents_with_openai_encoded_ids():\n",
        "    corpus_id_to_index_mapping = {_id: i for i, _id in enumerate(corpus_dataset['_id'])}\n",
        "    sentences = [f\"{corpus_dataset[corpus_id_to_index_mapping[_id]]['title']}. {corpus_dataset[corpus_id_to_index_mapping[_id]]['text']}\" for _id in np.load(f'{drive_root}/openai/encoded_ids.npy')]\n",
        "    sentence_embeddings = model.encode(sentences, show_progress_bar=True)\n",
        "    np.save(f'{drive_root}/{experiment_name}_embeddings_from_openai_encoded_ids.npy', sentence_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCryIUETbbtU"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "encode_documents_with_openai_encoded_ids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v239h-vY3jOU"
      },
      "outputs": [],
      "source": [
        "# Time of encoding 1000 first sentences with all-MiniLM-L6-v2\n",
        "# CPU (free colab):  \n",
        "# CPU times: user 2min 7s, sys: 365 ms, total: 2min 7s\n",
        "# Wall time: 2min 9s\n",
        "# GPU (free colab):\n",
        "# CPU times: user 5.57 s, sys: 1.26 s, total: 6.83 s\n",
        "# Wall time: 14.3 s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tI-nEb8YfBaV"
      },
      "outputs": [],
      "source": [
        "encode_queries_batch(0, None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdbD_Qo39Ms2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPIi84T6lc6y"
      },
      "source": [
        "### Similiarity computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ1JAX9PmAt8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRjVLsRpmiEZ"
      },
      "outputs": [],
      "source": [
        "# def to_tensor(embeddings_dict):\n",
        "#     return {_id: torch.tensor(embedding, device=device) for _id, embedding in embeddings_dict.items()}\n",
        "\n",
        "experiment_name = 2\n",
        "docs_ids = corpus_dataset['_id']\n",
        "docs_embeddings = torch.tensor(np.load(f\"{drive_root}/{experiment_name}_embeddings_0:None.npy\"), device=device)\n",
        "query_ids = queries_dataset['_id']\n",
        "query_embeddings = torch.tensor(np.load(f\"{drive_root}/{experiment_name}_query_embeddings_0:None.npy\"), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3OiYUQWQb72"
      },
      "outputs": [],
      "source": [
        "#  query_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkusCE8Fm9p2"
      },
      "outputs": [],
      "source": [
        "def true_scores(query_id):\n",
        "    pd_qrels = pd.DataFrame(qrels_dataset)    \n",
        "    pd_relevant_qrels = pd_qrels[pd_qrels['query-id'] == query_id]\n",
        "    qrels = dict(zip(pd_relevant_qrels['corpus-id'], pd_relevant_qrels['score']))\n",
        "    return [qrels[doc_id] if doc_id in qrels else 0 for doc_id in docs_ids]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rYvJtG2fuQY"
      },
      "outputs": [],
      "source": [
        "# ndcg_scores = []\n",
        "# for i, query_id in enumerate(query_ids):\n",
        "#     cos_sims = cosine_similarity(query_embeddings[i], docs_embeddings).cpu().numpy()\n",
        "#     _ndcg_score = ndcg_score([true_scores(int(query_id))], [cos_sims], k=10) \n",
        "#     ndcg_scores.append(_ndcg_score)\n",
        "#     print(_ndcg_score)\n",
        "ndcg_scores = [0.1100458831490401, 0.49276192198755825, 0.15362568563894313, 0.38431135260440824, 0.2899773651602119, 0.17010317160287547, 0.4085359184257957, 0.06625422345438896, 0.0, 0.13698471029831177, 0.3995688713838976, 0.46467597166437496, 0.39366982114002336, 0.4373524791503101, 0.2914893383161489, 0.8582425318466904, 0.496314133361996, 0.5708588662113935, 0.4826073387355251, 0.7799082337019198, 0.25880978898961277, 0.4440973278132557, 0.5698897789767065, 0.31093196555772146, 0.0, 0.23758350840568815, 0.8275534295258489, 0.5912463455842708, 0.6515402749735272, 0.9216017310213245, 0.4511074772466062, 0.0, 0.6203974344166848, 0.0, 0.03312711172719448, 0.6906478832608419, 0.4641183337813128, 0.36483361535360737, 0.9633180389503199, 0.9574284411791895, 0.9681896059005243, 0.8899541168509599, 0.8701249883466594, 0.7818745837832112, 0.6535073651712326, 0.866947989864271, 0.37307760663528433, 0.94497705842548, 0.333391619621485, 0.4225749983705864]\n",
        "# np.average(ndcg_scores) = 0.4770028047513443"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JeNyg7S6Mgj"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (14, 20)\n",
        "PROPS = {\n",
        "    'boxprops':{'edgecolor':'black', 'zorder': 2},\n",
        "    'medianprops':{'color':'black'},\n",
        "    'whiskerprops':{'color':'black'},\n",
        "    'capprops':{'color':'black'}\n",
        "}\n",
        "\n",
        "def generate_dists(_query_ids):\n",
        "\n",
        "    plt.figure()\n",
        "    labels = []\n",
        "    cos_sims = []\n",
        "    for i, query_id in enumerate(_query_ids):\n",
        "        current_cos_sims = cosine_similarity(query_embeddings[int(query_id) - 1], docs_embeddings).cpu().numpy()\n",
        "        cos_sims.extend(current_cos_sims)\n",
        "        labels.extend([f\"id = {query_id}; NDCG@10 = {ndcg_scores[int(query_id) - 1]:.2f}\" for i in range(len(current_cos_sims))])\n",
        "\n",
        "    print()\n",
        "    df=pd.DataFrame({'queries': labels, 'cos_sims': cos_sims})        \n",
        "    sns.violinplot(data=df, x='cos_sims', y='queries', inner=None, color='#5FBEF2')\n",
        "    sns.boxplot(data=df, x='cos_sims', y='queries', saturation=0.5, width=0.2, color='#CCF6FF', **PROPS)\n",
        "    # plt.legend()   \n",
        "    plt.grid(axis='x')\n",
        "    plt.savefig(f\"{drive_root}/violin_fig_{_query_ids[0]}-{_query_ids[-1]}.png\", dpi=300,  bbox_inches='tight')\n",
        "    plt.show()\n",
        "generate_dists(query_ids[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8cF6exCVD6O"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    generate_dists(query_ids[10*i:10*(i+1)]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_PhX8HRZ-4G"
      },
      "source": [
        "## OpenAI API:\n",
        "\n",
        "\n",
        "Estimate:\n",
        "We have money for ~ 100 Mtokens (Mega tokens, aka 10^6 tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDn1juqlU5rC"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "word_counts = []\n",
        "for text in tqdm(corpus_dataset['text']):\n",
        "    word_counts.append(len(text.translate(str.maketrans('', '', string.punctuation)).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWC11ojvmHIJ"
      },
      "outputs": [],
      "source": [
        "word_counts_df = pd.DataFrame(word_counts)\n",
        "word_counts_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnRBezOJTtUJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# sns.scatterplot(pd.DataFrame(word_counts))\n",
        "# sns.histplot(x=word_counts_df[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rh8jyFvVzpv"
      },
      "source": [
        "148 words per document * 1.33 tokens per word ~= 200 tokens/document\n",
        "\n",
        "Which gives us 500 000 documents. Which is almost 3 times the amount we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMe62578WN64"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WlZJaJ9Td5S"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from getpass import getpass\n",
        "openai.api_key = getpass(prompt=\"OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF1d8uLbnL-4"
      },
      "outputs": [],
      "source": [
        "# response = openai.Embedding.create(input = [\"Build advanced search, clustering, topic modeling, and classification functionality with our embeddings offering.\",\n",
        "#                                             \"Second sentense in a batch\"],\n",
        "#                                    model=\"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl0hNFQuRnmM"
      },
      "outputs": [],
      "source": [
        "with open(f\"{drive_root}/model_esponse.pkl\", \"rb\") as file:\n",
        "    model_response = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XNUQ7qSKMUb"
      },
      "outputs": [],
      "source": [
        "np.array(model_response['data'][0]['embedding'])[None,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDa-3UX53moe"
      },
      "outputs": [],
      "source": [
        "response[\"usage\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBmPPEFuhC_-"
      },
      "outputs": [],
      "source": [
        "from time import sleep\n",
        "import os\n",
        "def query_openai(query: str, max_try: int = 3, **kwargs):\n",
        "    for _ in range(max_try):\n",
        "        try:\n",
        "            response = openai.Embedding.create(input=query, model=\"text-embedding-ada-002\")\n",
        "            return response['data'][0]['embedding'], response[\"usage\"][\"total_tokens\"]\n",
        "            raise ValueError(f'Invalid request type: {req_type}')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Error in request: \", e)\n",
        "            sleep(3)\n",
        "\n",
        "    return None, None\n",
        "\n",
        "usd_per_token = 0.0004/1000\n",
        "# global_token_usage = 12087329 # And we missed this count for about 1000 documets in the beggining\n",
        "with open(f\"{drive_root}/global_token_usage.pkl\", \"rb\") as file:\n",
        "    global_token_usage = pickle.load(file)\n",
        "print(f\"Tokens spent: {global_token_usage}, Money spent: {global_token_usage*usd_per_token:.2f}$\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5RpvPnMRgE7"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "too_big_ids = []#[\"ij3ncdb6\", \"gvh0wdxn\", \"c4pt07zk\", \"1vimqhdp\", \"pd1g119c\"]\n",
        "\n",
        "\n",
        "def choose_not_encoded_ids(number: int, _embeddings_df) -> list:\n",
        "    already_mapped_ids = set(_embeddings_df['_id'])\n",
        "    total_ids_pool = set(corpus_dataset['_id'])\n",
        "    return list(np.random.choice(list(total_ids_pool - already_mapped_ids), size=number, replace=False))\n",
        "\n",
        "\n",
        "def openai_encode_batch(number: int):\n",
        "    error_count = 0\n",
        "    if os.path.exists(f'{drive_root}/openai/'):\n",
        "\n",
        "        global global_token_usage\n",
        "        with open(f\"{drive_root}/global_token_usage.pkl\", \"rb\") as file:\n",
        "            global_token_usage = pickle.load(file)\n",
        "\n",
        "        print(\"Loading existing embeddings\")\n",
        "        # _embeddings_df = pd.read_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv')\n",
        "        _embeddings_df = pd.read_pickle(f'{drive_root}/openai/text-embedding-ada-002_v2.pkl')\n",
        "        # print(\"Creating backup\")\n",
        "        # _embeddings_df.to_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv.backup.{datetime.now()}', index=False)\n",
        "        print(\"Finished backup\")\n",
        "\n",
        "        document_ids = choose_not_encoded_ids(number, _embeddings_df)\n",
        "\n",
        "        already_mapped_ids = set(_embeddings_df['_id'])\n",
        "\n",
        "        total_token_usage = 0\n",
        "        corpus_id_to_index_mapping = {_id: i for i, _id in enumerate(corpus_dataset['_id'])}\n",
        "        _pd_embedding_column_names = [str(i) for i in range(1536)]\n",
        "        _batch_df = pd.DataFrame(columns=_embeddings_df.columns)\n",
        "        with tqdm(total=number, position=0, leave=True) as pbar:\n",
        "            pbar.set_postfix_str(f\"Saved {len(_embeddings_df['_id'])} embeddings\")\n",
        "            for i, _id in enumerate(document_ids):\n",
        "                if _id not in already_mapped_ids:\n",
        "                    if _id not in too_big_ids:\n",
        "                        document_entry = corpus_dataset[corpus_id_to_index_mapping[_id]]\n",
        "                        sentence = f\"{document_entry['title']}. {document_entry['text']}\"\n",
        "                        embedding, tokens_used = query_openai(sentence)\n",
        "\n",
        "                        \n",
        "\n",
        "                        if embedding is not None:\n",
        "                            total_token_usage += tokens_used\n",
        "                            global_token_usage += tokens_used\n",
        "                            new_row = pd.DataFrame(np.array(embedding)[None, :], columns=_pd_embedding_column_names)\n",
        "                            new_row['_id'] = _id\n",
        "                            _batch_df = pd.concat([_batch_df, new_row])\n",
        "                            if (i - 501) % 1000 == 0:\n",
        "                                _embeddings_df = pd.concat([_embeddings_df, _batch_df])\n",
        "                                # _embeddings_df.to_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv', index=False)\n",
        "                                _embeddings_df.to_pickle(f'{drive_root}/openai/text-embedding-ada-002_v2.pkl')\n",
        "\n",
        "                                _batch_df = pd.DataFrame(columns=_embeddings_df.columns)\n",
        "\n",
        "                                pbar.set_postfix_str(f\"Saved {len(_embeddings_df['_id'])} embeddings\")\n",
        "\n",
        "                                np.save(f'{drive_root}/openai/encoded_ids.npy', list(_embeddings_df['_id']))\n",
        "                                with open(f\"{drive_root}/global_token_usage.pkl\", \"wb\") as file:\n",
        "                                    pickle.dump(global_token_usage, file)\n",
        "                            already_mapped_ids.add(_id)              \n",
        "                        else:\n",
        "                            print(f\"Error!: embedding is None for id {_id}\")\n",
        "                            error_count += 1\n",
        "                            if error_count > 10:\n",
        "                                break\n",
        "                    else:\n",
        "                        [print(f\"skipping id {_id} for being too fat\")]    \n",
        "                else:\n",
        "                    print(f'id {_id} is already embedded. skipping...')\n",
        "                pbar.update()\n",
        "            \n",
        "\n",
        "        _embeddings_df = pd.concat([_embeddings_df, _batch_df])\n",
        "        # _embeddings_df.to_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv', index=False)\n",
        "        _embeddings_df.to_pickle(f'{drive_root}/openai/text-embedding-ada-002_v2.pkl')\n",
        "        np.save(f'{drive_root}/openai/encoded_ids.npy', list(_embeddings_df['_id']))\n",
        "\n",
        "        print(f\"Token usage: {total_token_usage}, Global token usage: {global_token_usage}\"),\n",
        "        print(f\"Money spent: {usd_per_token*total_token_usage}, Global money spent: {usd_per_token*global_token_usage}\")\n",
        "        print(f\"Global documents encoded: {len(already_mapped_ids)}\")\n",
        "        with open(f\"{drive_root}/global_token_usage.pkl\", \"wb\") as file:\n",
        "            pickle.dump(global_token_usage, file)\n",
        "    else:\n",
        "        raise Exception(\"No path. Drive not mounted?\")\n",
        "\n",
        "\n",
        "openai_encode_batch(5)\n",
        "# This model's maximum context length is 8191 tokens however you requested 8510 tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embeddings_df = pd.read_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv')\n",
        "embeddings_df = pd.read_pickle(f'{drive_root}/openai/text-embedding-ada-002_v2.pkl')"
      ],
      "metadata": {
        "id": "KiGYHtByLkPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus_dataset['_id']) - 171332"
      ],
      "metadata": {
        "id": "T96zunNzGN-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(np.load(f'{drive_root}/openai/encoded_ids.npy'))"
      ],
      "metadata": {
        "id": "bHOEGwLoFAy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY3ITh-fHlCG"
      },
      "outputs": [],
      "source": [
        "# document_ids = ['ug7v899j', '9785vg6d']\n",
        "# corpus_dataset[2001]\n",
        "# pd.read_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv')\n",
        "# pd.read_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv.backup.2023-01-26 20:09:33.390034')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll8UAqgK0E1o"
      },
      "outputs": [],
      "source": [
        "# def openai_encode_queries():\n",
        "#     if os.path.exists(f'{drive_root}/openai/'):\n",
        "#         total_token_usage = 0\n",
        "#         for _id, query in tqdm(zip(queries_dataset[\"_id\"], queries_dataset['text']), total=50):\n",
        "#             filename = f'{drive_root}/openai/query-embedding-ada-002_v2_query_id_{_id}.npy'\n",
        "#             if not os.path.exists(filename):\n",
        "#                 embedding, tokens_used = query_openai(query)\n",
        "#                 total_token_usage += tokens_used\n",
        "\n",
        "#                 if embedding is not None:\n",
        "#                     np.save(filename, embedding)\n",
        "#                 else:\n",
        "#                     raise Exception()\n",
        "#             else:\n",
        "#                 print(f'id {_id} is already embedded. skipping...')\n",
        "#         global global_token_usage\n",
        "#         global_token_usage += total_token_usage\n",
        "#         print(f\"Token usage: {total_token_usage}, Global token usage: {global_token_usage}\"),\n",
        "#         print(f\"Money spent: {usd_per_token*total_token_usage}, Global money spent: {usd_per_token*global_token_usage}\")\n",
        "#     else:\n",
        "#         raise Exception(\"No path. Drive not mounted?\") \n",
        "# # openai_encode_queries()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6wsoCv4Yfom"
      },
      "source": [
        "Updated estimate: turns out, we have about 350 tokens per document which give us about 72k documents per token 10$\n",
        "\n",
        "Samples of tokens spent per 200 documents:\n",
        "\n",
        "- 200: 67324\n",
        "- 200: 64815\n",
        "- 200: 69195\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AF7PnsJ1SVu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGZYpFOh1TLL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTujgkG11NvR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvy9Bkzj5JlB"
      },
      "outputs": [],
      "source": [
        "# embeddings_df.to_csv(f'{drive_root}/openai/text-embedding-ada-002_v2.csv', index=False)\n",
        "embeddings_df = pd.read_pickle(f'{drive_root}/openai/text-embedding-ada-002_v2.pkl')\n",
        "# query_embeddings_df.to_csv(f'{drive_root}/openai/query-embedding-ada-002_v2.csv', index=False)\n",
        "query_embeddings_df = pd.read_csv(f'{drive_root}/openai/query-embedding-ada-002_v2.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyy5ZyjYFzz0"
      },
      "outputs": [],
      "source": [
        "def true_scores(query_id):\n",
        "    pd_qrels = pd.DataFrame(qrels_dataset)    \n",
        "    pd_relevant_qrels = pd_qrels[pd_qrels['query-id'] == int(query_id)]\n",
        "    qrels = dict(zip(pd_relevant_qrels['corpus-id'], pd_relevant_qrels['score']))\n",
        "    return [qrels[doc_id] if doc_id in qrels else 0 for doc_id in corpus_dataset['_id']]\n",
        "\n",
        "\n",
        "def true_scores_on_subset(query_id, corpus_ids_ordered_list):\n",
        "    pd_qrels = pd.DataFrame(qrels_dataset) \n",
        "    pd_relevant_qrels = pd_qrels[pd_qrels['query-id'] == int(query_id)]\n",
        "    qrels = dict(zip(pd_relevant_qrels['corpus-id'], pd_relevant_qrels['score']))\n",
        "    return [qrels[doc_id] if doc_id in qrels else 0 for doc_id in corpus_ids_ordered_list]\n",
        "\n",
        "\n",
        "def calculate_ndcg_scores_for_openai():\n",
        "    ndcg_scores = []\n",
        "    documents_embeddings = torch.tensor(embeddings_df.drop('_id', axis=1).to_numpy(), device=device)\n",
        "    for row, query_id in tqdm(zip(query_embeddings_df.drop('_id', axis=1).itertuples(index=False), query_embeddings_df['_id']), total=50):\n",
        "        query_embedding = torch.tensor(row, device=device)\n",
        "        cos_sims = cosine_similarity(query_embedding, documents_embeddings).cpu().numpy()\n",
        "        ndcg_scores.append(ndcg_score([true_scores_on_subset(query_id, list(embeddings_df['_id']))], [cos_sims], k=10))\n",
        "    return ndcg_scores\n",
        "\n",
        "# 55%:\n",
        "# openai_ndcg_scores = [0.5842585682254681, 1.0, 0.19218497482654184, 0.6442227883107535, 0.5437023030721884, 0.5009732673492617, 0.835780413693672, 0.5199967979955744, 0.2278403745052797, 0.6402900881481708, 0.17318663334822615, 0.3962756110857297, 0.5769766371786422, 0.6493026116472478, 0.7736502375634358, 0.9350624941733298, 0.8334430272969794, 0.4293039137177177, 0.48153499054313026, 0.8603818544462509, 0.3340514446642156, 0.9266360779006398, 0.7549357566339395, 0.7951657524814092, 0.9305687780632227, 0.5676818677290052, 0.7885497208855956, 0.5337225282363591, 0.8115558478722845, 0.9633180389503199, 0.2200917662980802, 0.12096982779948588, 0.2977473344546329, 0.3222722491219548, 0.46664232174566644, 0.8115558478722845, 0.4525070087200181, 0.4458221167281372, 0.8568270051237654, 0.9652843890316114, 0.9032521000738538, 0.9574284411791895, 1.0, 0.7407090992125821, 0.6168254041215527, 0.7389346265950472, 0.7123736502858729, 0.8178102956254404, 0.667905452944332, 0.5400096219094884]\n",
        "# 100%:\n",
        "openai_ndcg_scores = [0.8070980744903451, 1.0, 0.45484422125791807, 0.7207837995611228, 0.48268650276883, 0.5141863642577488, 1.0, 0.604685538711841, 0.1159354809201706, 0.7325140515171444, 0.40270657974248264, 0.19602998040580386, 0.5850494105837172, 0.6042846647453803, 0.8945466420562734, 0.8701249883466594, 0.9305687780632227, 0.5528346753887203, 0.4093911693176109, 1.0, 0.35687885840597894, 0.8276325935591538, 0.9266360779006398, 0.5661035610769689, 0.9305687780632227, 0.6036081270984908, 0.9652843890316114, 0.44821456061271253, 0.7763057112117956, 1.0, 0.5362234040097508, 0.19575819879232836, 0.17630010660342907, 0.473571703045486, 0.5685311061462373, 0.8643145546088338, 0.4209736685921866, 0.45403346208984086, 0.9305687780632227, 1.0, 0.9363792118010483, 1.0, 0.9574284411791895, 0.8244555950767655, 0.6941125739107519, 0.8945466420562734, 0.5384109300791363, 0.8801412713899903, 0.6882033310777197, 0.6769023376372896]\n",
        "# openai_ndcg_scores = calculate_ndcg_scores_for_openai()\n",
        "\n",
        "\n",
        "def calculate_ndcg_scores_sentence_transformer_full_dataset(experiment_name):\n",
        "    docs_miniLM_embeddings = torch.tensor(np.load(f\"{drive_root}/{experiment_name}_embeddings_0:None.npy\"), device=device)\n",
        "    query_miniLM_embeddings =  torch.tensor(np.load(f\"{drive_root}/{experiment_name}_query_embeddings_0:None.npy\"), device=device)\n",
        "\n",
        "    query_ids = queries_dataset['_id']\n",
        "\n",
        "    ndcg_scores = []\n",
        "    for i, query_id in enumerate(tqdm(query_ids)):\n",
        "        cos_sims = cosine_similarity(query_miniLM_embeddings[i], docs_miniLM_embeddings).cpu().numpy()\n",
        "        _ndcg_score = ndcg_score([true_scores(query_id)], [cos_sims], k=10)\n",
        "        ndcg_scores.append(_ndcg_score)\n",
        "\n",
        "    return(ndcg_scores)\n",
        "\n",
        "# def calculate_ndcg_scores_sentence_transformer_limited_to_openai(experiment_name):\n",
        "#     corpus_ids_sublist =  np.load(f'{drive_root}/openai/encoded_ids.npy').tolist()\n",
        "#     # docs_miniLM_embeddings_dict = {_id: embedding for embedding, _id in zip(np.load(f\"{drive_root}/{experiment_name}_embeddings_from_openai_encoded_ids.npy\"), np.load(f'{drive_root}/{experiment_name}_embeddings_from_openai_encoded_ids.npy')) \n",
        "#     #                       if _id in corpus_ids_subset}\n",
        "#     docs_miniLM_embeddings_ordered_by_corpus_ids_sublist = \\\n",
        "#         torch.tensor(np.load(f\"{drive_root}/{experiment_name}_embeddings_from_openai_encoded_ids.npy\"), device=device)\n",
        "#     query_miniLM_embeddings =  torch.tensor(np.load(f\"{drive_root}/{experiment_name}_query_embeddings_0:None.npy\"), device=device)\n",
        "\n",
        "#     query_ids = queries_dataset['_id']\n",
        "\n",
        "#     ndcg_scores = []\n",
        "#     for i, query_id in enumerate(tqdm(query_ids, total=len(query_ids))):\n",
        "#         cos_sims = cosine_similarity(query_miniLM_embeddings[i], docs_miniLM_embeddings_ordered_by_corpus_ids_sublist).cpu().numpy()\n",
        "#         _ndcg_score = ndcg_score([true_scores_on_subset(query_id, corpus_ids_sublist)], [cos_sims], k=10)\n",
        "#         ndcg_scores.append(_ndcg_score)\n",
        "\n",
        "#     return(ndcg_scores)\n",
        "\n",
        "\n",
        "# 55%:\n",
        "# minilm_ndcg_scores_masked_to_openai = [0.14317299487623458, 0.3316936730892072, 0.05502294157452005, 0.2489083270225946, 0.31871739979946917, 0.2628934232775421, 0.2528410271851775, 0.15744006533381547, 0.0, 0.07839826897867538, 0.2200917662980802, 0.414764616039942, 0.2489083270225946, 0.45449827622138, 0.32291168898636957, 0.7787274229518825, 0.25480737726646885, 0.6780494608112012, 0.5503088515264319, 1.0, 0.3668893220573615, 0.32891754857327965, 0.4585942246815616, 0.2883028873610169, 0.0, 0.1100458831490401, 0.6332196796270029, 0.5993294818993699, 0.7212476289592209, 0.9652843890316114, 0.25677372734776027, 0.0, 0.4440973278132557, 0.0, 0.06943122193677731, 0.6563033086078547, 0.34184825634124033, 0.3706398689768581, 1.0, 0.8627260553676397, 0.8354093773782707, 0.8899541168509599, 0.793584067764911, 0.7460573260980901, 0.6061131829864573, 0.5541432109622958, 0.4035015715464804, 0.8572048559638626, 0.25983227167304046, 0.2934556883974403]\n",
        "# minilm_ndcg_scores_masked_to_openai = calculate_ndcg_scores_sentence_transformer_limited_to_openai(2)\n",
        "# 100%:\n",
        "# minilm_ndcg_scores = calculate_ndcg_scores_sentence_transformer_full_dataset(2)\n",
        "minilm_ndcg_scores = [0.1100458831490401, 0.49276192198755825, 0.15362568563894313, 0.38431135260440824, 0.2899773651602119, 0.17010317160287547, 0.4085359184257957, 0.06625422345438896, 0.0, 0.13698471029831177, 0.3995688713838976, 0.46467597166437496, 0.39366982114002336, 0.4373524791503101, 0.2914893383161489, 0.8582425318466904, 0.496314133361996, 0.5708588662113935, 0.4826073387355251, 0.7799082337019198, 0.25880978898961277, 0.4440973278132557, 0.5648554320973912, 0.31093196555772146, 0.0, 0.23758350840568815, 0.8275534295258489, 0.5912463455842708, 0.6515402749735272, 0.9216017310213245, 0.4511074772466062, 0.0, 0.6203974344166848, 0.0, 0.03312711172719448, 0.6906478832608419, 0.4641183337813128, 0.36642211459480156, 0.9633180389503199, 0.9574284411791895, 0.9681896059005243, 0.8899541168509599, 0.8701249883466594, 0.7818745837832112, 0.6535073651712326, 0.866947989864271, 0.37307760663528433, 0.94497705842548, 0.333391619621485, 0.4225749983705864]\n",
        "\n",
        "# 55%:\n",
        "# roberta_large_ndcg_scores_masked_to_openai = calculate_ndcg_scores_sentence_transformer_limited_to_openai('roberta-large')\n",
        "# roberta_large_ndcg_scores_masked_to_openai = [0.1526174419698506, 0.6410457898283652, 0.5313216166124811, 0.32730659600127, 0.6493956800157978, 0.19200765187283184, 0.20248323207250618, 0.5670429581667767, 0.43483530571065243, 0.15139734109600997, 0.0, 0.1159354809201706, 0.3417690923079354, 0.28510343554781303, 0.10281992268828936, 0.8409421369006526, 0.8066756304994496, 0.7493668840625239, 0.45783805463287947, 0.914856882358379, 0.4200295294463964, 0.6745711375739727, 0.6056113032143303, 0.23992089480238074, 0.1388624438735545, 0.2940945979596687, 0.6994739030813918, 0.58874982024632, 0.42679693286721787, 0.8572048559638626, 0.06625422345438896, 0.0, 0.3360272472182508, 0.06943122193677725, 0.0, 0.6580831550106186, 0.5220328596374271, 0.7206210196320116, 0.9652843890316114, 0.9118499466982855, 0.6633398556941038, 1.0, 0.6717589890736099, 0.8058779736165045, 0.6024171237592955, 0.610206738115618, 0.38541299932114076, 0.8482378089219645, 0.1585070397409811, 0.4142137926815757]\n",
        "# 100%:\n",
        "# roberta_large_ndcg_scores = calculate_ndcg_scores_sentence_transformer_full_dataset('roberta-large')\n",
        "roberta_large_ndcg_scores =[0.1100458831490401, 0.6659485553357843, 0.5670647108745396, 0.47095699092922255, 0.5423640154200349, 0.11101497038372705, 0.21501812929496164, 0.3495957416360196, 0.43128045638816687, 0.06625422345438896, 0.0, 0.031810394099475836, 0.27566553123096654, 0.3787833386759353, 0.06943122193677725, 0.7753366239771086, 0.8300792533881372, 0.7407090992125821, 0.37111125655399296, 0.7849818707050383, 0.3864438606792726, 0.8200685179888283, 0.7459781620647852, 0.3701854920515037, 0.2489083270225946, 0.1794771050858174, 0.715550648768261, 0.8200685179888283, 0.20483424751859086, 0.7721596254947203, 0.07839826897867538, 0.0, 0.21101571757181772, 0.06943122193677725, 0.0, 0.7264127302306636, 0.442017625612159, 0.735488778956926, 0.9305687780632227, 0.9526058178152246, 0.8098106737790872, 1.0, 0.5933607200949346, 0.7338014706205254, 0.6100364306762963, 0.933745776545611, 0.3012042966046398, 1.0, 0.29922683201146266, 0.5164235740297879]\n",
        "\n",
        "# 55%:\n",
        "# sgpt_125M_ndcg_scores_masked_to_openai = calculate_ndcg_scores_sentence_transformer_limited_to_openai('SGPT-125M-weightedmean-nli-bitfit')\n",
        "# sgpt_125M_ndcg_scores_masked_to_openai = [0.03919913448933769, 0.0, 0.4730272350194151, 0.18844415212771548, 0.0, 0.30635490529973475, 0.5328965452000554, 0.4886446891881014, 0.0, 0.4131279133289227, 0.0, 0.0, 0.22883763735188417, 0.0, 0.15840915256850244, 0.13147032541923082, 0.38028902407143617, 0.7803864358037507, 0.05502294157452005, 0.7510916729774054, 0.3125291152215463, 0.513528549750033, 0.1862566260583299, 0.06625422345438896, 0.5215784827120726, 0.4671223597454321, 0.5766882048947065, 0.7702043899253147, 0.4576752747037683, 0.4250887937457822, 0.06362078819895167, 0.042571558820810505, 0.5258863957667049, 0.07839826897867538, 0.1243422521309587, 0.28886316319212685, 0.3347092591719315, 0.4751168795544826, 0.818005721474525, 0.9681896059005243, 0.9668728882728055, 0.8990301655772223, 0.9019353824461352, 0.933745776545611, 0.6020780239162796, 0.0, 0.1388624438735545, 0.1498113059440708, 0.2212088779621395, 0.2200917662980802]\n",
        "# 100%:\n",
        "\n",
        "# 55%:\n",
        "# sgpt_1_3B_ndcg_scores_masked_to_openai = calculate_ndcg_scores_sentence_transformer_limited_to_openai('SGPT-1.3B-weightedmean-nli-bitfit')\n",
        "# sgpt_1_3B_ndcg_scores_masked_to_openai = [0.042571558820810505, 0.2344065099232998, 0.4854538877975283, 0.0, 0.36966643130673016, 0.4440973278132557, 0.5462574254588145, 0.5033242827953465, 0.0, 0.3295708308392408, 0.0, 0.0, 0.2017507857732402, 0.0, 0.4035015715464804, 0.7971389170873964, 0.5226027621892171, 0.6209886708112745, 0.1017640840433747, 0.8643145546088338, 0.6594803070902429, 0.7381222142123632, 0.46056057476285306, 0.1610425878239397, 0.77523873680463, 0.5017100640839689, 0.7534494445524138, 0.7799082337019198, 0.4193979998881981, 0.39076460427111054, 0.530100330015507, 0.315046288661204, 0.660068415675558, 0.1585070397409811, 0.42010339045270617, 0.28634598975246917, 0.48499195269313716, 0.9363792118010483, 0.9276737537834677, 0.94497705842548, 0.8553475075669357, 0.9305687780632227, 1.0, 0.8087436993719216, 0.4711936318646434, 0.17318663334822615, 0.40957306400643717, 0.8324140018367822, 0.6461194268314838, 0.2200917662980802]\n",
        "# 100%:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llsaHYeXajK7"
      },
      "outputs": [],
      "source": [
        "repr(roberta_large_ndcg_scores)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"NDCG@10 scores:\")\n",
        "print(f\"MiniLM                               {np.average(minilm_ndcg_scores):.2f}\")\n",
        "print(f\"roberta-large-v1                     {np.average(roberta_large_ndcg_scores):.2f}\")\n",
        "# print(f\"SGPT-125M-weightedmean-nli-bitfit    {np.average(sgpt_125M_ndcg_scores_masked_to_openai):.2f}\")\n",
        "# print(f\"SGPT-1.3B-weightedmean-nli-bitfit    {np.average(sgpt_1_3B_ndcg_scores_masked_to_openai):.2f}\")\n",
        "print(f\"OpenAI embedding-ada-002_v2          {np.average(openai_ndcg_scores):.2f}\")\n",
        "print(f\"calculated on 100% of TREC-COVID dataset\")\n",
        "# print(f\"calculated on ~{len(embeddings_df['_id']) / len(corpus_dataset['_id']) * 100 :.0f}% of TREC-COVID dataset\")"
      ],
      "metadata": {
        "id": "TvqC0FR7gVuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "NDCG@10 scores:\n",
        "MiniLM                               0.43\n",
        "roberta-large-v1                     0.48\n",
        "SGPT-125M-weightedmean-nli-bitfit    0.36\n",
        "SGPT-1.3B-weightedmean-nli-bitfit    0.48\n",
        "OpenAI embedding-ada-002_v2          0.64\n",
        "calculated on ~55% of TREC-COVID dataset\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Self reported scores (ndcg@10):\n",
        "\n",
        "e5-large                            0.78\n",
        "e5-base                             0.80\n",
        "e5-small                            0.77\n",
        "SGPT-5.8B-weightedmean-nli-bitfit   0.55\n",
        "```\n",
        "https://docs.google.com/spreadsheets/d/1L8aACyPaXrL8iEelJLGqlMqXKPX2oSP_R10pZoy77Ns/edit#gid=0\n",
        "\n"
      ],
      "metadata": {
        "id": "OBpZCeGdSZj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating pics for openai only"
      ],
      "metadata": {
        "id": "Nc0n_7N0N9-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (14, 20)\n",
        "PROPS = {\n",
        "    'boxprops':{'edgecolor':'black', 'zorder': 2},\n",
        "    'medianprops':{'color':'black'},\n",
        "    'whiskerprops':{'color':'black'},\n",
        "    'capprops':{'color':'black'}\n",
        "}\n",
        "\n",
        "# corpus_ids_sublist = list(embeddings_df['_id'])\n",
        "# corpus_ids_subset = set(corpus_ids_sublist)\n",
        "\n",
        "# experiment_name = 2\n",
        "# docs_miniLM_embeddings_dict = {_id: embedding for embedding, _id in zip(np.load(f\"{drive_root}/{experiment_name}_embeddings_0:None.npy\"), corpus_dataset['_id']) \n",
        "#                         if _id in corpus_ids_subset}\n",
        "# docs_miniLM_embeddings_ordered_by_corpus_ids_sublist = \\\n",
        "#     torch.tensor(np.array([docs_miniLM_embeddings_dict[_id] for _id in corpus_ids_sublist]), device=device)\n",
        "# query_miniLM_embeddings =  torch.tensor(np.load(f\"{drive_root}/{experiment_name}_query_embeddings_0:None.npy\"), device=device)\n",
        "\n",
        "# docs_ids = corpus_dataset['_id']\n",
        "query_ids = queries_dataset['_id']\n",
        "\n",
        "def generate_dists(_query_ids):\n",
        "\n",
        "    plt.figure()\n",
        "    labels = []\n",
        "    cos_sims = []\n",
        "    colors = []\n",
        "    for i, query_id in enumerate([int(_id) for _id in _query_ids]):\n",
        "        openai_query_embedding = torch.tensor(query_embeddings_df[query_embeddings_df['_id'] == query_id].drop('_id', axis=1).to_numpy(), device=device)\n",
        "        openai_doc_embeddings = torch.tensor(embeddings_df.drop('_id', axis=1).to_numpy(), device=device)\n",
        "        openai_cos_sims = cosine_similarity(openai_query_embedding, openai_doc_embeddings).cpu().numpy()\n",
        "        cos_sims.extend(openai_cos_sims)\n",
        "        labels.extend([f\"query_id = {query_id}; NDCG@10 = {openai_ndcg_scores[query_id - 1]:.2f}\" for i in range(len(openai_cos_sims))])\n",
        "        colors.extend([f\"openai\" for i in range(len(openai_cos_sims))])\n",
        "\n",
        "    # print()\n",
        "    df=pd.DataFrame({'queries': labels, 'cos_sims': cos_sims, 'colors': colors})        \n",
        "    sns.violinplot(data=df, x='cos_sims', y='queries', inner=None, color='#5FBEF2')\n",
        "    sns.boxplot(data=df, x='cos_sims', y='queries', saturation=0.5, width=0.2, color='#CCF6FF', **PROPS)\n",
        "    # plt.legend()   \n",
        "    plt.title(\"openai cos_sims distribution\")\n",
        "    plt.grid(axis='x')\n",
        "    plt.savefig(f\"{drive_root}/openai_violin_fig_{_query_ids[0]}-{_query_ids[-1]}.png\", dpi=300,  bbox_inches='tight')\n",
        "    plt.show()\n",
        "generate_dists(query_ids[0:10])"
      ],
      "metadata": {
        "id": "gcEqEt6PqyXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKDP8VmZ5iZA"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    generate_dists(query_ids[10*i:10*(i+1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whqo7gmnuImz"
      },
      "outputs": [],
      "source": [
        "## Generating pics for both\n",
        "plt.rcParams[\"figure.figsize\"] = (14, 20)\n",
        "PROPS = {\n",
        "    'boxprops':{'edgecolor':'black', 'zorder': 2},\n",
        "    'medianprops':{'color':'black'},\n",
        "    'whiskerprops':{'color':'black'},\n",
        "    'capprops':{'color':'black'}\n",
        "}\n",
        "\n",
        "corpus_ids_sublist = list(embeddings_df['_id'])\n",
        "corpus_ids_subset = set(corpus_ids_sublist)\n",
        "\n",
        "experiment_name = 2\n",
        "docs_miniLM_embeddings_dict = {_id: embedding for embedding, _id in zip(np.load(f\"{drive_root}/{experiment_name}_embeddings_0:None.npy\"), corpus_dataset['_id']) \n",
        "                        if _id in corpus_ids_subset}\n",
        "docs_miniLM_embeddings_ordered_by_corpus_ids_sublist = \\\n",
        "    torch.tensor(np.array([docs_miniLM_embeddings_dict[_id] for _id in corpus_ids_sublist]), device=device)\n",
        "query_miniLM_embeddings =  torch.tensor(np.load(f\"{drive_root}/{experiment_name}_query_embeddings_0:None.npy\"), device=device)\n",
        "\n",
        "docs_ids = corpus_dataset['_id']\n",
        "query_ids = queries_dataset['_id']\n",
        "\n",
        "def generate_dists(_query_ids):\n",
        "\n",
        "    plt.figure()\n",
        "    labels = []\n",
        "    cos_sims = []\n",
        "    colors = []\n",
        "    for i, query_id in enumerate([int(_id) for _id in _query_ids]):\n",
        "        openai_query_embedding = torch.tensor(query_embeddings_df[query_embeddings_df['_id'] == query_id].drop('_id', axis=1).to_numpy(), device=device)\n",
        "        openai_doc_embeddings = torch.tensor(embeddings_df.drop('_id', axis=1).to_numpy(), device=device)\n",
        "        openai_cos_sims = cosine_similarity(openai_query_embedding, openai_doc_embeddings).cpu().numpy()\n",
        "        cos_sims.extend(openai_cos_sims)\n",
        "        labels.extend([f\"query_id = {query_id}; NDCG@10 = {openai_ndcg_scores[query_id - 1]:.2f}\" for i in range(len(openai_cos_sims))])\n",
        "        colors.extend([f\"OpenAI embedding-ada-002_v2\" for i in range(len(openai_cos_sims))])\n",
        "\n",
        "        minilm_cos_sims = cosine_similarity(query_miniLM_embeddings[query_id - 1], docs_miniLM_embeddings_ordered_by_corpus_ids_sublist).cpu().numpy()\n",
        "        cos_sims.extend(minilm_cos_sims)\n",
        "        assert len(minilm_cos_sims) == len(openai_cos_sims)\n",
        "        labels.extend([f\"query_id = {query_id}; NDCG@10 = {minilm_ndcg_scores_masked_to_openai[query_id - 1]:.2f}\" for i in range(len(minilm_cos_sims))])\n",
        "        colors.extend([f\"all-MiniLM-L6-v2\" for i in range(len(minilm_cos_sims))])\n",
        "\n",
        "    df=pd.DataFrame({'queries': labels, 'cos_sims': cos_sims, 'colors': colors})        \n",
        "    sns.violinplot(data=df, x='cos_sims', y='queries', hue='colors', inner=None, dodge=False, \n",
        "                   palette={\"OpenAI embedding-ada-002_v2\": \"#2B8E46\", \"all-MiniLM-L6-v2\": '#5FBEF2'})\n",
        "    ax = sns.boxplot(data=df, x='cos_sims', y='queries', hue='colors', saturation=0.5, width=0.2, dodge=False, **PROPS,\n",
        "                palette={\"OpenAI embedding-ada-002_v2\": \"#D8F9DA\", \"all-MiniLM-L6-v2\": '#CCF6FF'})\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    ax.legend(handles=handles[0:2], labels=labels[0:2])\n",
        "    sns.move_legend(ax, \"upper left\")\n",
        "    # plt.legend()   \n",
        "    plt.title(\"openai cos_sims distribution\")\n",
        "    plt.grid(axis='x')\n",
        "    plt.savefig(f\"{drive_root}/comparison_violin_fig_{_query_ids[0]}-{_query_ids[-1]}.png\", dpi=300,  bbox_inches='tight')\n",
        "    plt.show()\n",
        "generate_dists(query_ids[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bJoPkOP6Pt8"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    generate_dists(query_ids[5*i:5*(i+1)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umZtv8Fxn1Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2TrhqqF7ZNq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7Ic_i4zX_Qx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}