{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Exploring categories\n",
    "# with open(\"/mnt/HDD/tmp/arxiv-metadata-oai-snapshot.json\", \"r\") as dataset_file:\n",
    "#     dataset = []\n",
    "#     for line in tqdm(dataset_file):\n",
    "#         dataset.append(json.loads(line)['categories'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Selected categories:\n",
    "\n",
    "stat.ML: Machine Learning\n",
    "cs.LG: Machine Learning\n",
    "cs.CL: Computation and Language\n",
    "cs.CV: Computer Vision and Pattern Recognition\n",
    "cs.AI: Artificial Intelligence\n",
    "~~cond-mat.dis-nn: Disordered Systems and Neural Networks~~"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# ml_categories = [\"stat.ML\", \"cs.AI\", \"cs.CL\", \"cs.CV\", \"cs.LG\"]\n",
    "# print(f\"all: {len([0 for cat_str in dataset if np.all([category in cat_str for category in ml_categories])])}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# any: 253542\n",
    "# all: 19\n",
    "# {\"stat.ML\": 57543,\n",
    "#  \"cs.AI\": 57379,\n",
    "#  \"cs.CL\": 41573,\n",
    "#  \"cs.CV\": 88800,\n",
    "#  \"cs.LG\": 129563} = 374858 total category markers per 253542 articles => every article has about 1.5 relevant categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# ml_categories = [\"stat.ML\", \"cs.AI\", \"cs.CL\", \"cs.CV\", \"cs.LG\"]\n",
    "# with open(\"/mnt/HDD/tmp/arxiv-metadata-oai-snapshot.json\", \"r\") as dataset_file:\n",
    "#     with open(\"/mnt/HDD/tmp/arxiv-metadata-oai-snapshot-only-ml-categories.json\", \"w\") as only_ml_file:\n",
    "#         for line in tqdm(dataset_file):\n",
    "#             cat_str = json.loads(line)['categories']\n",
    "#             if np.any([category in cat_str for category in ml_categories]):\n",
    "#                 only_ml_file.write(line)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253542it [00:10, 25162.64it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"/mnt/HDD/tmp/arxiv-metadata-oai-snapshot-only-ml-categories.json\", \"r\") as dataset_file:\n",
    "    df = pd.DataFrame.from_records((json.loads(line) for line in tqdm(dataset_file)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi',\n       'report-no', 'categories', 'license', 'abstract', 'versions',\n       'update_date', 'authors_parsed'],\n      dtype='object')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "!git clone -b dependency_version_fix https://github.com/ArtemPt239/easy-elasticsearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -e easy-elasticsearch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# This code will install a docker container with elasticsearch into your system\n",
    "# Don't forget to delete it once you finished\n",
    "from benchmarking import BaseSearchEngine\n",
    "import re\n",
    "from easy_elasticsearch import ElasticSearchBM25\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "class BM25Search(BaseSearchEngine):\n",
    "    def __init__(self):\n",
    "        self.esbm25 = None\n",
    "\n",
    "    def preprocess(self, text: str) -> str:\n",
    "        t = re.sub('\\(|\\)|:|,|;|\\.|’|”|“|\\?|%|>|<', '', text)\n",
    "        t = re.sub('/', ' ', t)\n",
    "        t = t.replace(\"'\",'')\n",
    "\n",
    "        _stopwords = set(stopwords.words('english'))\n",
    "        return ' '.join([word for word in t.split() if word not in _stopwords])\n",
    "\n",
    "    def index(self, dataset: pd.DataFrame, ids_column_name: str = 'id', abstract_column_name: str = 'abstract'):\n",
    "        pool = {_id: self.preprocess(text) for _id, text in tqdm(zip(dataset[ids_column_name], dataset[abstract_column_name]))}\n",
    "        self.esbm25 = ElasticSearchBM25(pool)\n",
    "\n",
    "    def retrieve(self, query: str, amount: int):\n",
    "        return self.esbm25.query(self.preprocess(query), topk=amount)\n",
    "\n",
    "    # def retrieve_scores(self, query: str, amount: int):\n",
    "    #     # return self.esbm25.score(self.preprocess(query), [_id for _id in self.retrieve(query, amount)])\n",
    "    #     pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253542it [01:18, 3231.91it/s]\n",
      "2023-02-13 14:29:22 - No host running. Now start a new ES service via docker\n",
      "\n",
      "Usage:  docker [OPTIONS] COMMAND\n",
      "\n",
      "A self-sufficient runtime for containers\n",
      "\n",
      "Options:\n",
      "      --config string      Location of client config files (default\n",
      "                           \"/home/hououin/.docker\")\n",
      "  -c, --context string     Name of the context to use to connect to the\n",
      "                           daemon (overrides DOCKER_HOST env var and\n",
      "                           default context set with \"docker context use\")\n",
      "  -D, --debug              Enable debug mode\n",
      "  -H, --host list          Daemon socket(s) to connect to\n",
      "  -l, --log-level string   Set the logging level\n",
      "                           (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\")\n",
      "                           (default \"info\")\n",
      "      --tls                Use TLS; implied by --tlsverify\n",
      "      --tlscacert string   Trust certs signed only by this CA (default\n",
      "                           \"/home/hououin/.docker/ca.pem\")\n",
      "      --tlscert string     Path to TLS certificate file (default\n",
      "                           \"/home/hououin/.docker/cert.pem\")\n",
      "      --tlskey string      Path to TLS key file (default\n",
      "                           \"/home/hououin/.docker/key.pem\")\n",
      "      --tlsverify          Use TLS and verify the remote\n",
      "  -v, --version            Print version information and quit\n",
      "\n",
      "Management Commands:\n",
      "  builder     Manage builds\n",
      "  compose*    Docker Compose (Docker Inc., v2.14.1)\n",
      "  config      Manage Docker configs\n",
      "  container   Manage containers\n",
      "  context     Manage contexts\n",
      "  image       Manage images\n",
      "  manifest    Manage Docker image manifests and manifest lists\n",
      "  network     Manage networks\n",
      "  node        Manage Swarm nodes\n",
      "  plugin      Manage plugins\n",
      "  secret      Manage Docker secrets\n",
      "  service     Manage services\n",
      "  stack       Manage Docker stacks\n",
      "  swarm       Manage Swarm\n",
      "  system      Manage Docker\n",
      "  trust       Manage trust on Docker images\n",
      "  volume      Manage volumes\n",
      "\n",
      "Commands:\n",
      "  attach      Attach local standard input, output, and error streams to a running container\n",
      "  build       Build an image from a Dockerfile\n",
      "  commit      Create a new image from a container's changes\n",
      "  cp          Copy files/folders between a container and the local filesystem\n",
      "  create      Create a new container\n",
      "  diff        Inspect changes to files or directories on a container's filesystem\n",
      "  events      Get real time events from the server\n",
      "  exec        Run a command in a running container\n",
      "  export      Export a container's filesystem as a tar archive\n",
      "  history     Show the history of an image\n",
      "  images      List images\n",
      "  import      Import the contents from a tarball to create a filesystem image\n",
      "  info        Display system-wide information\n",
      "  inspect     Return low-level information on Docker objects\n",
      "  kill        Kill one or more running containers\n",
      "  load        Load an image from a tar archive or STDIN\n",
      "  login       Log in to a Docker registry\n",
      "  logout      Log out from a Docker registry\n",
      "  logs        Fetch the logs of a container\n",
      "  pause       Pause all processes within one or more containers\n",
      "  port        List port mappings or a specific mapping for the container\n",
      "  ps          List containers\n",
      "  pull        Pull an image or a repository from a registry\n",
      "  push        Push an image or a repository to a registry\n",
      "  rename      Rename a container\n",
      "  restart     Restart one or more containers\n",
      "  rm          Remove one or more containers\n",
      "  rmi         Remove one or more images\n",
      "  run         Run a command in a new container\n",
      "  save        Save one or more images to a tar archive (streamed to STDOUT by default)\n",
      "  search      Search the Docker Hub for images\n",
      "  start       Start one or more stopped containers\n",
      "  stats       Display a live stream of container(s) resource usage statistics\n",
      "  stop        Stop one or more running containers\n",
      "  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE\n",
      "  top         Display the running processes of a container\n",
      "  unpause     Unpause all processes within one or more containers\n",
      "  update      Update configuration of one or more containers\n",
      "  version     Show the Docker version information\n",
      "  wait        Block until one or more containers stop, then print their exit codes\n",
      "\n",
      "Run 'docker COMMAND --help' for more information on a command.\n",
      "\n",
      "\u001B[1mTo get more help with docker, check out our guides at https://docs.docker.com/go/guides/\u001B[0m\n",
      "2023-02-13 14:29:22 - Running command: `docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" --detach --name easy-elasticsearch-node1676284162 docker.elastic.co/elasticsearch/elasticsearch:7.9.1`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfda5d8ecf22363ca5cbcedf6e9084f74fc73334b77bbd7368a9d284449789c6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:29:24 - Waiting for the ES service to be well started. Maximum time waiting: 100s\n",
      " 27%|██▋       | 27/100 [00:27<01:14,  1.03s/it]\n",
      "2023-02-13 14:29:51 - Successfully started a ES container with name \"easy-elasticsearch-node1676284162\"\n",
      "2023-02-13 14:29:51 - Successfully built connection to ES service at http://localhost:9200\n",
      "2023-02-13 14:29:51 - No index found and now do indexing\n",
      "100%|██████████| 508/508 [01:11<00:00,  7.13it/s]\n",
      "2023-02-13 14:31:10 - Indexing work done: 253542 documents indexed\n",
      "2023-02-13 14:31:10 - All set up.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 4.49 s, total: 1min 30s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time #this benchmark might be unrepresentative because colbert in background\n",
    "searcher = BM25Search()\n",
    "searcher.index(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from benchmarking import benchmark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 s, sys: 77.8 ms, total: 33.6 s\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "benchmark(df, searcher, \"results/bm25\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
