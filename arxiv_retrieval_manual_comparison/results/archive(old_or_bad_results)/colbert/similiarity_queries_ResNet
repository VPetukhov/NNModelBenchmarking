1: 
A neural network approach to ordinal regression
  Ordinal regression is an important type of learning, which has properties of
both classification and regression. Here we describe a simple and effective
approach to adapt a traditional neural network to learn ordinal categories. Our
approach is a generalization of the perceptron method for ordinal regression.
On several benchmark datasets, our method (NNRank) outperforms a neural network
classification method. Compared with the ordinal regression methods using
Gaussian processes and support vector machines, NNRank achieves comparable
performance. Moreover, NNRank has the advantages of traditional neural
networks: learning in both online and batch modes, handling very large training
datasets, and making rapid predictions. These features make NNRank a useful and
complementary tool for large-scale data processing tasks such as information
retrieval, web page ranking, collaborative filtering, and protein ranking in
Bioinformatics.

2: 
An Adaptive Strategy for the Classification of G-Protein Coupled
  Receptors
  One of the major problems in computational biology is the inability of
existing classification models to incorporate expanding and new domain
knowledge. This problem of static classification models is addressed in this
paper by the introduction of incremental learning for problems in
bioinformatics. Many machine learning tools have been applied to this problem
using static machine learning structures such as neural networks or support
vector machines that are unable to accommodate new information into their
existing models. We utilize the fuzzy ARTMAP as an alternate machine learning
system that has the ability of incrementally learning new data as it becomes
available. The fuzzy ARTMAP is found to be comparable to many of the widespread
machine learning systems. The use of an evolutionary strategy in the selection
and combination of individual classifiers into an ensemble system, coupled with
the incremental learning ability of the fuzzy ARTMAP is proven to be suitable
as a pattern classifier. The algorithm presented is tested using data from the
G-Coupled Protein Receptors Database and shows good accuracy of 83%. The system
presented is also generally applicable, and can be used in problems in genomics
and proteomics.

3: 
Multi-Dimensional Recurrent Neural Networks
  Recurrent neural networks (RNNs) have proved effective at one dimensional
sequence learning tasks, such as speech and online handwriting recognition.
Some of the properties that make RNNs suitable for such tasks, for example
robustness to input warping, and the ability to access contextual information,
are also desirable in multidimensional domains. However, there has so far been
no direct way of applying RNNs to data with more than one spatio-temporal
dimension. This paper introduces multi-dimensional recurrent neural networks
(MDRNNs), thereby extending the potential applicability of RNNs to vision,
video processing, medical imaging and many other areas, while avoiding the
scaling problems that have plagued other multi-dimensional models. Experimental
results are provided for two image segmentation tasks.

4: 
Bayesian approach to rough set
  This paper proposes an approach to training rough set models using Bayesian
framework trained using Markov Chain Monte Carlo (MCMC) method. The prior
probabilities are constructed from the prior knowledge that good rough set
models have fewer rules. Markov Chain Monte Carlo sampling is conducted through
sampling in the rough set granule space and Metropolis algorithm is used as an
acceptance criteria. The proposed method is tested to estimate the risk of HIV
given demographic data. The results obtained shows that the proposed approach
is able to achieve an average accuracy of 58% with the accuracy varying up to
66%. In addition the Bayesian rough set give the probabilities of the estimated
HIV status as well as the linguistic rules describing how the demographic
parameters drive the risk of HIV.

5: 
The Parameter-Less Self-Organizing Map algorithm
  The Parameter-Less Self-Organizing Map (PLSOM) is a new neural network
algorithm based on the Self-Organizing Map (SOM). It eliminates the need for a
learning rate and annealing schemes for learning rate and neighbourhood size.
We discuss the relative performance of the PLSOM and the SOM and demonstrate
some tasks in which the SOM fails but the PLSOM performs satisfactory. Finally
we discuss some example applications of the PLSOM and present a proof of
ordering under certain limited conditions.

