1: 
On the Performance of Generative Adversarial Network (GAN) Variants: A
  Clinical Data Study
  Generative Adversarial Network (GAN) is a useful type of Neural Networks in
various types of applications including generative models and feature
extraction. Various types of GANs are being researched with different insights,
resulting in a diverse family of GANs with a better performance in each
generation. This review focuses on various GANs categorized by their common
traits.

2: 
Generative Adversarial Nets: Can we generate a new dataset based on only
  one training set?
  A generative adversarial network (GAN) is a class of machine learning
frameworks designed by Goodfellow et al. in 2014. In the GAN framework, the
generative model is pitted against an adversary: a discriminative model that
learns to determine whether a sample is from the model distribution or the data
distribution. GAN generates new samples from the same distribution as the
training set. In this work, we aim to generate a new dataset that has a
different distribution from the training set. In addition, the Jensen-Shannon
divergence between the distributions of the generative and training datasets
can be controlled by some target $\delta \in [0, 1]$. Our work is motivated by
applications in generating new kinds of rice that have similar characteristics
as good rice.

3: 
Semi-Supervised Learning with GANs: Revisiting Manifold Regularization
  GANS are powerful generative models that are able to model the manifold of
natural images. We leverage this property to perform manifold regularization by
approximating the Laplacian norm using a Monte Carlo approximation that is
easily computed with the GAN. When incorporated into the feature-matching GAN
of Improved GAN, we achieve state-of-the-art results for GAN-based
semi-supervised learning on the CIFAR-10 dataset, with a method that is
significantly easier to implement than competing methods.

4: 
StudioGAN: A Taxonomy and Benchmark of GANs for Image Synthesis
  Generative Adversarial Network (GAN) is one of the state-of-the-art
generative models for realistic image synthesis. While training and evaluating
GAN becomes increasingly important, the current GAN research ecosystem does not
provide reliable benchmarks for which the evaluation is conducted consistently
and fairly. Furthermore, because there are few validated GAN implementations,
researchers devote considerable time to reproducing baselines. We study the
taxonomy of GAN approaches and present a new open-source library named
StudioGAN. StudioGAN supports 7 GAN architectures, 9 conditioning methods, 4
adversarial losses, 13 regularization modules, 3 differentiable augmentations,
7 evaluation metrics, and 5 evaluation backbones. With our training and
evaluation protocol, we present a large-scale benchmark using various datasets
(CIFAR10, ImageNet, AFHQv2, FFHQ, and Baby/Papa/Granpa-ImageNet) and 3
different evaluation backbones (InceptionV3, SwAV, and Swin Transformer).
Unlike other benchmarks used in the GAN community, we train representative
GANs, including BigGAN, StyleGAN2, and StyleGAN3, in a unified training
pipeline and quantify generation performance with 7 evaluation metrics. The
benchmark evaluates other cutting-edge generative models(e.g., StyleGAN-XL,
ADM, MaskGIT, and RQ-Transformer). StudioGAN provides GAN implementations,
training, and evaluation scripts with the pre-trained weights. StudioGAN is
available at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN.

5: 
Texture Synthesis with Spatial Generative Adversarial Networks
  Generative adversarial networks (GANs) are a recent approach to train
generative models of data, which have been shown to work particularly well on
image data. In the current paper we introduce a new model for texture synthesis
based on GAN learning. By extending the input noise distribution space from a
single vector to a whole spatial tensor, we create an architecture with
properties well suited to the task of texture synthesis, which we call spatial
GAN (SGAN). To our knowledge, this is the first successful completely
data-driven texture synthesis method based on GANs.
  Our method has the following features which make it a state of the art
algorithm for texture synthesis: high image quality of the generated textures,
very high scalability w.r.t. the output texture size, fast real-time forward
generation, the ability to fuse multiple diverse source images in complex
textures. To illustrate these capabilities we present multiple experiments with
different classes of texture images and use cases. We also discuss some
limitations of our method with respect to the types of texture images it can
synthesize, and compare it to other neural techniques for texture generation.

