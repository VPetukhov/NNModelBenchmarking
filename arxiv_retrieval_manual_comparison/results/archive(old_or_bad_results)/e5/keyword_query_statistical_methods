1: 
Evaluating Urbanization from Satellite and Aerial Images by means of a
  statistical approach to the texture analysis
  Statistical methods are usually applied in the processing of digital images
for the analysis of the textures displayed by them. Aiming to evaluate the
urbanization of a given location from satellite or aerial images, here we
consider a simple processing to distinguish in them the 'urban' from the
'rural' texture. The method is based on the mean values and the standard
deviations of the colour tones of image pixels. The processing of the input
images allows to obtain some maps from which a quantitative evaluation of the
textures can be obtained.

2: 
On the role of benchmarking data sets and simulations in method
  comparison studies
  Method comparisons are essential to provide recommendations and guidance for
applied researchers, who often have to choose from a plethora of available
approaches. While many comparisons exist in the literature, these are often not
neutral but favour a novel method. Apart from the choice of design and a proper
reporting of the findings, there are different approaches concerning the
underlying data for such method comparison studies. Most manuscripts on
statistical methodology rely on simulation studies and provide a single
real-world data set as an example to motivate and illustrate the methodology
investigated. In the context of supervised learning, in contrast, methods are
often evaluated using so-called benchmarking data sets, i.e. real-world data
that serve as gold standard in the community. Simulation studies, on the other
hand, are much less common in this context. The aim of this paper is to
investigate differences and similarities between these approaches, to discuss
their advantages and disadvantages and ultimately to develop new approaches to
the evaluation of methods picking the best of both worlds. To this aim, we
borrow ideas from different contexts such as mixed methods research and
Clinical Scenario Evaluation.

3: 
Applications of statistical causal inference in software engineering
  This paper reviews existing work in software engineering that applies
statistical causal inference methods. These methods aim at estimating causal
effects from observational data. The review covers 32 papers published between
2010 and 2022. Our results show that the application of statistical causal
inference methods is relatively recent and that the corresponding research
community remains relatively fragmented.

4: 
Why Comparing Single Performance Scores Does Not Allow to Draw
  Conclusions About Machine Learning Approaches
  Developing state-of-the-art approaches for specific tasks is a major driving
force in our research community. Depending on the prestige of the task,
publishing it can come along with a lot of visibility. The question arises how
reliable are our evaluation methodologies to compare approaches?
  One common methodology to identify the state-of-the-art is to partition data
into a train, a development and a test set. Researchers can train and tune
their approach on some part of the dataset and then select the model that
worked best on the development set for a final evaluation on unseen test data.
Test scores from different approaches are compared, and performance differences
are tested for statistical significance.
  In this publication, we show that there is a high risk that a statistical
significance in this type of evaluation is not due to a superior learning
approach. Instead, there is a high risk that the difference is due to chance.
For example for the CoNLL 2003 NER dataset we observed in up to 26% of the
cases type I errors (false positives) with a threshold of p < 0.05, i.e.,
falsely concluding a statistically significant difference between two identical
approaches.
  We prove that this evaluation setup is unsuitable to compare learning
approaches. We formalize alternative evaluation setups based on score
distributions.

5: 
Notes on computational-to-statistical gaps: predictions using
  statistical physics
  In these notes we describe heuristics to predict computational-to-statistical
gaps in certain statistical problems. These are regimes in which the underlying
statistical problem is information-theoretically possible although no efficient
algorithm exists, rendering the problem essentially unsolvable for large
instances. The methods we describe here are based on mature, albeit
non-rigorous, tools from statistical physics.
  These notes are based on a lecture series given by the authors at the Courant
Institute of Mathematical Sciences in New York City, on May 16th, 2017.

