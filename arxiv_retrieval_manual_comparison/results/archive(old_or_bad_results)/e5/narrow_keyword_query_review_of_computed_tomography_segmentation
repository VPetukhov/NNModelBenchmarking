1: 
CT Image Enhancement Using Stacked Generative Adversarial Networks and
  Transfer Learning for Lesion Segmentation Improvement
  Automated lesion segmentation from computed tomography (CT) is an important
and challenging task in medical image analysis. While many advancements have
been made, there is room for continued improvements. One hurdle is that CT
images can exhibit high noise and low contrast, particularly in lower dosages.
To address this, we focus on a preprocessing method for CT images that uses
stacked generative adversarial networks (SGAN) approach. The first GAN reduces
the noise in the CT image and the second GAN generates a higher resolution
image with enhanced boundaries and high contrast. To make up for the absence of
high quality CT images, we detail how to synthesize a large number of low- and
high-quality natural images and use transfer learning with progressively larger
amounts of CT images. We apply both the classic GrabCut method and the modern
holistically nested network (HNN) to lesion segmentation, testing whether SGAN
can yield improved lesion segmentation. Experimental results on the DeepLesion
dataset demonstrate that the SGAN enhancements alone can push GrabCut
performance over HNN trained on original images. We also demonstrate that HNN +
SGAN performs best compared against four other enhancement methods, including
when using only a single GAN.

2: 
An automatic COVID-19 CT segmentation network using spatial and channel
  attention mechanism
  The coronavirus disease (COVID-19) pandemic has led to a devastating effect
on the global public health. Computed Tomography (CT) is an effective tool in
the screening of COVID-19. It is of great importance to rapidly and accurately
segment COVID-19 from CT to help diagnostic and patient monitoring. In this
paper, we propose a U-Net based segmentation network using attention mechanism.
As not all the features extracted from the encoders are useful for
segmentation, we propose to incorporate an attention mechanism including a
spatial and a channel attention, to a U-Net architecture to re-weight the
feature representation spatially and channel-wise to capture rich contextual
relationships for better feature representation. In addition, the focal tversky
loss is introduced to deal with small lesion segmentation. The experiment
results, evaluated on a COVID-19 CT segmentation dataset where 473 CT slices
are available, demonstrate the proposed method can achieve an accurate and
rapid segmentation on COVID-19 segmentation. The method takes only 0.29 second
to segment a single CT slice. The obtained Dice Score, Sensitivity and
Specificity are 83.1%, 86.7% and 99.3%, respectively.

3: 
Spark in the Dark: Evaluating Encoder-Decoder Pairs for COVID-19 CT's
  Semantic Segmentation
  With the COVID-19 global pandemic, computerassisted diagnoses of medical
images have gained a lot of attention, and robust methods of Semantic
Segmentation of Computed Tomography (CT) turned highly desirable. Semantic
Segmentation of CT is one of many research fields of automatic detection of
Covid-19 and was widely explored since the Covid19 outbreak. In the robotic
field, Semantic Segmentation of organs and CTs are widely used in robots
developed for surgery tasks. As new methods and new datasets are proposed
quickly, it becomes apparent the necessity of providing an extensive evaluation
of those methods. To provide a standardized comparison of different
architectures across multiple recently proposed datasets, we propose in this
paper an extensive benchmark of multiple encoders and decoders with a total of
120 architectures evaluated in five datasets, with each dataset being validated
through a five-fold cross-validation strategy, totaling 3.000 experiments. To
the best of our knowledge, this is the largest evaluation in number of
encoders, decoders, and datasets proposed in the field of Covid-19 CT
segmentation.

4: 
Interactive segmentation of medical images through fully convolutional
  neural networks
  Image segmentation plays an essential role in medicine for both diagnostic
and interventional tasks. Segmentation approaches are either manual,
semi-automated or fully-automated. Manual segmentation offers full control over
the quality of the results, but is tedious, time consuming and prone to
operator bias. Fully automated methods require no human effort, but often
deliver sub-optimal results without providing users with the means to make
corrections. Semi-automated approaches keep users in control of the results by
providing means for interaction, but the main challenge is to offer a good
trade-off between precision and required interaction. In this paper we present
a deep learning (DL) based semi-automated segmentation approach that aims to be
a "smart" interactive tool for region of interest delineation in medical
images. We demonstrate its use for segmenting multiple organs on computed
tomography (CT) of the abdomen. Our approach solves some of the most pressing
clinical challenges: (i) it requires only one to a few user clicks to deliver
excellent 2D segmentations in a fast and reliable fashion; (ii) it can
generalize to previously unseen structures and "corner cases"; (iii) it
delivers results that can be corrected quickly in a smart and intuitive way up
to an arbitrary degree of precision chosen by the user and (iv) ensures high
accuracy. We present our approach and compare it to other techniques and
previous work to show the advantages brought by our method.

5: 
A Bottom-Up Approach for Automatic Pancreas Segmentation in Abdominal CT
  Scans
  Organ segmentation is a prerequisite for a computer-aided diagnosis (CAD)
system to detect pathologies and perform quantitative analysis. For
anatomically high-variability abdominal organs such as the pancreas, previous
segmentation works report low accuracies when comparing to organs like the
heart or liver. In this paper, a fully-automated bottom-up method is presented
for pancreas segmentation, using abdominal computed tomography (CT) scans. The
method is based on a hierarchical two-tiered information propagation by
classifying image patches. It labels superpixels as pancreas or not via pooling
patch-level confidences on 2D CT slices over-segmented by the Simple Linear
Iterative Clustering approach. A supervised random forest (RF) classifier is
trained on the patch level and a two-level cascade of RFs is applied at the
superpixel level, coupled with multi-channel feature extraction, respectively.
On six-fold cross-validation using 80 patient CT volumes, we achieved 68.8%
Dice coefficient and 57.2% Jaccard Index, comparable to or slightly better than
published state-of-the-art methods.

