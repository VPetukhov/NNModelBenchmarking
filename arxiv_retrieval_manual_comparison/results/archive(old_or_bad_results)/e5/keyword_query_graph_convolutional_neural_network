1: 
Adaptive Graph Convolutional Neural Networks
  Graph Convolutional Neural Networks (Graph CNNs) are generalizations of
classical CNNs to handle graph data such as molecular data, point could and
social networks. Current filters in graph CNNs are built for fixed and shared
graph structure. However, for most real data, the graph structures varies in
both size and connectivity. The paper proposes a generalized and flexible graph
CNN taking data of arbitrary graph structure as input. In that way a
task-driven adaptive graph is learned for each graph data while training. To
efficiently learn the graph, a distance metric learning is proposed. Extensive
experiments on nine graph-structured datasets have demonstrated the superior
performance improvement on both convergence speed and predictive accuracy.

2: 
Exploring Structure-Adaptive Graph Learning for Robust Semi-Supervised
  Classification
  Graph Convolutional Neural Networks (GCNNs) are generalizations of CNNs to
graph-structured data, in which convolution is guided by the graph topology. In
many cases where graphs are unavailable, existing methods manually construct
graphs or learn task-driven adaptive graphs. In this paper, we propose Graph
Learning Neural Networks (GLNNs), which exploit the optimization of graphs (the
adjacency matrix in particular) from both data and tasks. Leveraging on
spectral graph theory, we propose the objective of graph learning from a
sparsity constraint, properties of a valid adjacency matrix as well as a graph
Laplacian regularizer via maximum a posteriori estimation. The optimization
objective is then integrated into the loss function of the GCNN, which adapts
the graph topology to not only labels of a specific task but also the input
data. Experimental results show that our proposed GLNN outperforms
state-of-the-art approaches over widely adopted social network datasets and
citation network datasets for semi-supervised classification.

3: 
Architectural Implications of Embedding Dimension during GCN on CPU and
  GPU
  Graph Neural Networks (GNNs) are a class of neural networks designed to
extract information from the graphical structure of data. Graph Convolutional
Networks (GCNs) are a widely used type of GNN for transductive graph learning
problems which apply convolution to learn information from graphs. GCN is a
challenging algorithm from an architecture perspective due to inherent
sparsity, low data reuse, and massive memory capacity requirements. Traditional
neural algorithms exploit the high compute capacity of GPUs to achieve high
performance for both inference and training. The architectural decision to use
a GPU for GCN inference is a question explored in this work. GCN on both CPU
and GPU was characterized in order to better understand the implications of
graph size, embedding dimension, and sampling on performance.

4: 
Graph Learning-Convolutional Networks
  Recently, graph Convolutional Neural Networks (graph CNNs) have been widely
used for graph data representation and semi-supervised learning tasks. However,
existing graph CNNs generally use a fixed graph which may be not optimal for
semi-supervised learning tasks. In this paper, we propose a novel Graph
Learning-Convolutional Network (GLCN) for graph data representation and
semi-supervised learning. The aim of GLCN is to learn an optimal graph
structure that best serves graph CNNs for semi-supervised learning by
integrating both graph learning and graph convolution together in a unified
network architecture. The main advantage is that in GLCN, both given labels and
the estimated labels are incorporated and thus can provide useful 'weakly'
supervised information to refine (or learn) the graph construction and also to
facilitate the graph convolution operation in GLCN for unknown label
estimation. Experimental results on seven benchmarks demonstrate that GLCN
significantly outperforms state-of-the-art traditional fixed structure based
graph CNNs.

5: 
Topology Adaptive Graph Convolutional Networks
  Spectral graph convolutional neural networks (CNNs) require approximation to
the convolution to alleviate the computational complexity, resulting in
performance loss. This paper proposes the topology adaptive graph convolutional
network (TAGCN), a novel graph convolutional network defined in the vertex
domain. We provide a systematic way to design a set of fixed-size learnable
filters to perform convolutions on graphs. The topologies of these filters are
adaptive to the topology of the graph when they scan the graph to perform
convolution. The TAGCN not only inherits the properties of convolutions in CNN
for grid-structured data, but it is also consistent with convolution as defined
in graph signal processing. Since no approximation to the convolution is
needed, TAGCN exhibits better performance than existing spectral CNNs on a
number of data sets and is also computationally simpler than other recent
methods.

